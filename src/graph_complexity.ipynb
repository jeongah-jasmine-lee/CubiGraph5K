{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote summary of all floorplans by difficulty to ./graph_complexity_info_3493.txt\n",
      "Any files that caused errors are logged in ./error.txt\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import re\n",
    "import ast\n",
    "import os\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "\n",
    "def read_adjacency_from_file(path):\n",
    "    with open(path, 'r') as f:\n",
    "        content = f.read()\n",
    "    match = re.search(r\"Room Adjacency List:\\s*(\\{.*\\})\", content)\n",
    "    if not match:\n",
    "        raise ValueError(f\"Could not find 'Room Adjacency List' in {path}.\")\n",
    "    return ast.literal_eval(match.group(1))\n",
    "\n",
    "def build_graph(adjacency_dict):\n",
    "    G = nx.Graph()\n",
    "    for room, neighbors in adjacency_dict.items():\n",
    "        for nbr, w in neighbors.items():\n",
    "            G.add_edge(room, nbr, weight=w)\n",
    "    return G\n",
    "\n",
    "def largest_connected_subgraph(G):\n",
    "    if nx.is_connected(G):\n",
    "        return G\n",
    "    largest_cc = max(nx.connected_components(G), key=len)\n",
    "    return G.subgraph(largest_cc).copy()\n",
    "\n",
    "def compute_indices(G):\n",
    "    V = G.number_of_nodes()\n",
    "    E = G.number_of_edges()\n",
    "    EI = V + E\n",
    "    MI = (E - V + 1) / (2.0 * V - 5) if (2 * V - 5) > 0 else 0.0\n",
    "    H = largest_connected_subgraph(G)\n",
    "    ASPLI = nx.average_shortest_path_length(H, weight='weight')\n",
    "    return EI, MI, ASPLI\n",
    "\n",
    "def compute_difficulty(ei, mi, aspli,\n",
    "                       ei_min, ei_max,\n",
    "                       mi_min, mi_max,\n",
    "                       aspli_min, aspli_max):\n",
    "    def safe_norm(x, xmin, xmax):\n",
    "        return 0.0 if xmax == xmin else (x - xmin) / (xmax - xmin)\n",
    "    EI_n    = safe_norm(ei,    ei_min,    ei_max)\n",
    "    MI_n    = safe_norm(mi,    mi_min,    mi_max)\n",
    "    ASPLI_n = safe_norm(aspli, aspli_min, aspli_max)\n",
    "    D = (EI_n + MI_n + ASPLI_n) / 3.0\n",
    "    if D < 0.33:\n",
    "        label = \"easy\"\n",
    "    elif D < 0.66:\n",
    "        label = \"medium\"\n",
    "    else:\n",
    "        label = \"hard\"\n",
    "    return label, D\n",
    "\n",
    "def main():\n",
    "    pattern = '../cubicasa5k-3493-cubigraph/*/*/info.txt'\n",
    "    info_files = glob.glob(pattern)\n",
    "\n",
    "    # 1) First pass: compute raw indices\n",
    "    file_indices = {}\n",
    "    error_log_path = \"./error.txt\"\n",
    "    open(error_log_path, 'w').close()\n",
    "\n",
    "    for info_path in info_files:\n",
    "        try:\n",
    "            adj = read_adjacency_from_file(info_path)\n",
    "            G   = build_graph(adj)\n",
    "            file_indices[info_path] = compute_indices(G)\n",
    "        except Exception as e:\n",
    "            with open(error_log_path, 'a') as ef:\n",
    "                ef.write(f\"{os.path.dirname(info_path)} -> {e}\\n\")\n",
    "            continue\n",
    "\n",
    "    if not file_indices:\n",
    "        print(\"No valid graphs found. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # 2) Determine global min/max\n",
    "    all_EI    = [v[0] for v in file_indices.values()]\n",
    "    all_MI    = [v[1] for v in file_indices.values()]\n",
    "    all_ASPLI = [v[2] for v in file_indices.values()]\n",
    "    EI_min, EI_max       = min(all_EI),    max(all_EI)\n",
    "    MI_min, MI_max       = min(all_MI),    max(all_MI)\n",
    "    ASPLI_min, ASPLI_max = min(all_ASPLI), max(all_ASPLI)\n",
    "\n",
    "    # 3) Second pass: classify & store scores\n",
    "    difficulty_map   = defaultdict(list)   # difficulty -> list of (path, score)\n",
    "    for path, (ei, mi, aspli) in file_indices.items():\n",
    "        diff, score = compute_difficulty(\n",
    "            ei, mi, aspli,\n",
    "            EI_min, EI_max,\n",
    "            MI_min, MI_max,\n",
    "            ASPLI_min, ASPLI_max\n",
    "        )\n",
    "        difficulty_map[diff].append((path, score))\n",
    "\n",
    "        # append into each info.txt if not already present\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        if \"Graph difficulty:\" not in content:\n",
    "            with open(path, 'a', encoding='utf-8') as f:\n",
    "                f.write(f\"\\nRaw Indices: EI={ei}, MI={mi:.4f}, ASPLI={aspli:.4f}\\n\")\n",
    "                f.write(f\"score:  {score}\\n\")\n",
    "                f.write(f\"Graph difficulty: {diff}\\n\\n\")\n",
    "\n",
    "    # 4) Write summary with scores\n",
    "    summary_file = \"./graph_complexity_info_3493.txt\"\n",
    "    with open(summary_file, 'w') as sf:\n",
    "        sf.write(\"Summary of all floorplans by difficulty:\\n\\n\")\n",
    "        for label in [\"easy\", \"medium\", \"hard\"]:\n",
    "            entries = difficulty_map.get(label, [])\n",
    "            sf.write(f\"{label}: {len(entries)} file(s)\\n\")\n",
    "            for path, score in entries:\n",
    "                sf.write(f\"   {path}  (score: {score:.6f})\\n\")\n",
    "            sf.write(\"\\n\")\n",
    "\n",
    "    print(f\"Wrote summary of all floorplans by difficulty to {summary_file}\")\n",
    "    print(f\"Any files that caused errors are logged in {error_log_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote summary of all floorplans by difficulty to ./graph_complexity_info_666.txt\n",
      "Any files that caused errors are logged in ./error.txt\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import re\n",
    "import ast\n",
    "import os\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "\n",
    "def read_adjacency_from_file(path):\n",
    "    with open(path, 'r') as f:\n",
    "        content = f.read()\n",
    "    match = re.search(r\"Room Adjacency List:\\s*(\\{.*\\})\", content)\n",
    "    if not match:\n",
    "        raise ValueError(f\"Could not find 'Room Adjacency List' in {path}.\")\n",
    "    return ast.literal_eval(match.group(1))\n",
    "\n",
    "def build_graph(adjacency_dict):\n",
    "    G = nx.Graph()\n",
    "    for room, neighbors in adjacency_dict.items():\n",
    "        for nbr, w in neighbors.items():\n",
    "            G.add_edge(room, nbr, weight=w)\n",
    "    return G\n",
    "\n",
    "def largest_connected_subgraph(G):\n",
    "    if nx.is_connected(G):\n",
    "        return G\n",
    "    largest_cc = max(nx.connected_components(G), key=len)\n",
    "    return G.subgraph(largest_cc).copy()\n",
    "\n",
    "def compute_indices(G):\n",
    "    V = G.number_of_nodes()\n",
    "    E = G.number_of_edges()\n",
    "    EI = V + E\n",
    "    MI = (E - V + 1) / (2.0 * V - 5) if (2 * V - 5) > 0 else 0.0\n",
    "    H = largest_connected_subgraph(G)\n",
    "    ASPLI = nx.average_shortest_path_length(H, weight='weight')\n",
    "    return EI, MI, ASPLI\n",
    "\n",
    "def compute_difficulty(ei, mi, aspli,\n",
    "                       ei_min, ei_max,\n",
    "                       mi_min, mi_max,\n",
    "                       aspli_min, aspli_max):\n",
    "    def safe_norm(x, xmin, xmax):\n",
    "        return 0.0 if xmax == xmin else (x - xmin) / (xmax - xmin)\n",
    "    EI_n    = safe_norm(ei,    ei_min,    ei_max)\n",
    "    MI_n    = safe_norm(mi,    mi_min,    mi_max)\n",
    "    ASPLI_n = safe_norm(aspli, aspli_min, aspli_max)\n",
    "    D = (EI_n + MI_n + ASPLI_n) / 3.0\n",
    "    if D < 0.33:\n",
    "        label = \"easy\"\n",
    "    elif D < 0.66:\n",
    "        label = \"medium\"\n",
    "    else:\n",
    "        label = \"hard\"\n",
    "    return label, D\n",
    "\n",
    "def main():\n",
    "    pattern = '../cubicasa5k-666/*/*/info.txt'\n",
    "    info_files = glob.glob(pattern)\n",
    "\n",
    "    # 1) First pass: compute raw indices\n",
    "    file_indices = {}\n",
    "    error_log_path = \"./error.txt\"\n",
    "    open(error_log_path, 'w').close()\n",
    "\n",
    "    for info_path in info_files:\n",
    "        try:\n",
    "            adj = read_adjacency_from_file(info_path)\n",
    "            G   = build_graph(adj)\n",
    "            file_indices[info_path] = compute_indices(G)\n",
    "        except Exception as e:\n",
    "            with open(error_log_path, 'a') as ef:\n",
    "                ef.write(f\"{os.path.dirname(info_path)} -> {e}\\n\")\n",
    "            continue\n",
    "\n",
    "    if not file_indices:\n",
    "        print(\"No valid graphs found. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # 2) Determine global min/max\n",
    "    all_EI    = [v[0] for v in file_indices.values()]\n",
    "    all_MI    = [v[1] for v in file_indices.values()]\n",
    "    all_ASPLI = [v[2] for v in file_indices.values()]\n",
    "    EI_min, EI_max       = min(all_EI),    max(all_EI)\n",
    "    MI_min, MI_max       = min(all_MI),    max(all_MI)\n",
    "    ASPLI_min, ASPLI_max = min(all_ASPLI), max(all_ASPLI)\n",
    "\n",
    "    # 3) Second pass: classify & store scores\n",
    "    difficulty_map   = defaultdict(list)   # difficulty -> list of (path, score)\n",
    "    for path, (ei, mi, aspli) in file_indices.items():\n",
    "        diff, score = compute_difficulty(\n",
    "            ei, mi, aspli,\n",
    "            EI_min, EI_max,\n",
    "            MI_min, MI_max,\n",
    "            ASPLI_min, ASPLI_max\n",
    "        )\n",
    "        difficulty_map[diff].append((path, score))\n",
    "\n",
    "        # append into each info.txt if not already present\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        if \"Graph difficulty:\" not in content:\n",
    "            with open(path, 'a', encoding='utf-8') as f:\n",
    "                f.write(f\"\\nRaw Indices: EI={ei}, MI={mi:.4f}, ASPLI={aspli:.4f}\\n\")\n",
    "                f.write(f\"score:  {score}\\n\")\n",
    "                f.write(f\"Graph difficulty: {diff}\\n\\n\")\n",
    "\n",
    "    # 4) Write summary with scores\n",
    "    summary_file = \"./graph_complexity_info_666.txt\"\n",
    "    with open(summary_file, 'w') as sf:\n",
    "        sf.write(\"Summary of all floorplans by difficulty:\\n\\n\")\n",
    "        for label in [\"easy\", \"medium\", \"hard\"]:\n",
    "            entries = difficulty_map.get(label, [])\n",
    "            sf.write(f\"{label}: {len(entries)} file(s)\\n\")\n",
    "            for path, score in entries:\n",
    "                sf.write(f\"   {path}  (score: {score:.6f})\\n\")\n",
    "            sf.write(\"\\n\")\n",
    "\n",
    "    print(f\"Wrote summary of all floorplans by difficulty to {summary_file}\")\n",
    "    print(f\"Any files that caused errors are logged in {error_log_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote summary of all floorplans by difficulty to ./graph_complexity_info_69.txt\n",
      "Any files that caused errors are logged in ./error.txt\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import re\n",
    "import ast\n",
    "import os\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "\n",
    "def read_adjacency_from_file(path):\n",
    "    with open(path, 'r') as f:\n",
    "        content = f.read()\n",
    "    match = re.search(r\"Room Adjacency List:\\s*(\\{.*\\})\", content)\n",
    "    if not match:\n",
    "        raise ValueError(f\"Could not find 'Room Adjacency List' in {path}.\")\n",
    "    return ast.literal_eval(match.group(1))\n",
    "\n",
    "def build_graph(adjacency_dict):\n",
    "    G = nx.Graph()\n",
    "    for room, neighbors in adjacency_dict.items():\n",
    "        for nbr, w in neighbors.items():\n",
    "            G.add_edge(room, nbr, weight=w)\n",
    "    return G\n",
    "\n",
    "def largest_connected_subgraph(G):\n",
    "    if nx.is_connected(G):\n",
    "        return G\n",
    "    largest_cc = max(nx.connected_components(G), key=len)\n",
    "    return G.subgraph(largest_cc).copy()\n",
    "\n",
    "def compute_indices(G):\n",
    "    V = G.number_of_nodes()\n",
    "    E = G.number_of_edges()\n",
    "    EI = V + E\n",
    "    MI = (E - V + 1) / (2.0 * V - 5) if (2 * V - 5) > 0 else 0.0\n",
    "    H = largest_connected_subgraph(G)\n",
    "    ASPLI = nx.average_shortest_path_length(H, weight='weight')\n",
    "    return EI, MI, ASPLI\n",
    "\n",
    "def compute_difficulty(ei, mi, aspli,\n",
    "                       ei_min, ei_max,\n",
    "                       mi_min, mi_max,\n",
    "                       aspli_min, aspli_max):\n",
    "    def safe_norm(x, xmin, xmax):\n",
    "        return 0.0 if xmax == xmin else (x - xmin) / (xmax - xmin)\n",
    "    EI_n    = safe_norm(ei,    ei_min,    ei_max)\n",
    "    MI_n    = safe_norm(mi,    mi_min,    mi_max)\n",
    "    ASPLI_n = safe_norm(aspli, aspli_min, aspli_max)\n",
    "    D = (EI_n + MI_n + ASPLI_n) / 3.0\n",
    "    if D < 0.33:\n",
    "        label = \"easy\"\n",
    "    elif D < 0.66:\n",
    "        label = \"medium\"\n",
    "    else:\n",
    "        label = \"hard\"\n",
    "    return label, D\n",
    "\n",
    "def main():\n",
    "    pattern = '../cubicasa5k-sample-69-with-hard/*/*/*/info.txt'\n",
    "    info_files = glob.glob(pattern)\n",
    "\n",
    "    # 1) First pass: compute raw indices\n",
    "    file_indices = {}\n",
    "    error_log_path = \"./error.txt\"\n",
    "    open(error_log_path, 'w').close()\n",
    "\n",
    "    for info_path in info_files:\n",
    "        try:\n",
    "            adj = read_adjacency_from_file(info_path)\n",
    "            G   = build_graph(adj)\n",
    "            file_indices[info_path] = compute_indices(G)\n",
    "        except Exception as e:\n",
    "            with open(error_log_path, 'a') as ef:\n",
    "                ef.write(f\"{os.path.dirname(info_path)} -> {e}\\n\")\n",
    "            continue\n",
    "\n",
    "    if not file_indices:\n",
    "        print(\"No valid graphs found. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # 2) Determine global min/max\n",
    "    all_EI    = [v[0] for v in file_indices.values()]\n",
    "    all_MI    = [v[1] for v in file_indices.values()]\n",
    "    all_ASPLI = [v[2] for v in file_indices.values()]\n",
    "    EI_min, EI_max       = min(all_EI),    max(all_EI)\n",
    "    MI_min, MI_max       = min(all_MI),    max(all_MI)\n",
    "    ASPLI_min, ASPLI_max = min(all_ASPLI), max(all_ASPLI)\n",
    "\n",
    "    # 3) Second pass: classify & store scores\n",
    "    difficulty_map   = defaultdict(list)   # difficulty -> list of (path, score)\n",
    "    for path, (ei, mi, aspli) in file_indices.items():\n",
    "        diff, score = compute_difficulty(\n",
    "            ei, mi, aspli,\n",
    "            EI_min, EI_max,\n",
    "            MI_min, MI_max,\n",
    "            ASPLI_min, ASPLI_max\n",
    "        )\n",
    "        difficulty_map[diff].append((path, score))\n",
    "\n",
    "        # append into each info.txt if not already present\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        if \"Graph difficulty:\" not in content:\n",
    "            with open(path, 'a', encoding='utf-8') as f:\n",
    "                f.write(f\"\\nRaw Indices: EI={ei}, MI={mi:.4f}, ASPLI={aspli:.4f}\\n\")\n",
    "                f.write(f\"score:  {score}\\n\")\n",
    "                f.write(f\"Graph difficulty: {diff}\\n\\n\")\n",
    "\n",
    "    # 4) Write summary with scores\n",
    "    summary_file = \"./graph_complexity_info_69.txt\"\n",
    "    with open(summary_file, 'w') as sf:\n",
    "        sf.write(\"Summary of all floorplans by difficulty:\\n\\n\")\n",
    "        for label in [\"easy\", \"medium\", \"hard\"]:\n",
    "            entries = difficulty_map.get(label, [])\n",
    "            sf.write(f\"{label}: {len(entries)} file(s)\\n\")\n",
    "            for path, score in entries:\n",
    "                sf.write(f\"   {path}  (score: {score:.6f})\\n\")\n",
    "            sf.write(\"\\n\")\n",
    "\n",
    "    print(f\"Wrote summary of all floorplans by difficulty to {summary_file}\")\n",
    "    print(f\"Any files that caused errors are logged in {error_log_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "floorplan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
